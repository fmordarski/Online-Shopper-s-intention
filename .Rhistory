y_hat <- predict(fit, test_set)
sqrt(mean((y_hat - test_set$y)^2))
})
mean(rmse)
sd(rmse)
set.seed(1)
library(tidyverse)
library(purrr)
library(pdftools)
install.packages("tidyverse")
install.packages("pdftools")
library(tidyverse)
library(purrr)
library(pdftools)
library(tidyverse)
library(purrr)
library(pdftools)
fn <- system.file("extdata", "RD-Mortality-Report_2015-18-180531.pdf", package="dslabs")
dat <- map_df(str_split(pdf_text(fn), "\n"), function(s){
s <- str_trim(s)
header_index <- str_which(s, "2015")[1]
tmp <- str_split(s[header_index], "\\s+", simplify = TRUE)
month <- tmp[1]
header <- tmp[-1]
tail_index  <- str_which(s, "Total")
n <- str_count(s, "\\d+")
out <- c(1:header_index, which(n==1), which(n>=28), tail_index:length(s))
s[-out] %>%
str_remove_all("[^\\d\\s]") %>%
str_trim() %>%
str_split_fixed("\\s+", n = 6) %>%
.[,1:5] %>%
as_data_frame() %>%
setNames(c("day", header)) %>%
mutate(month = month,
day = as.numeric(day)) %>%
gather(year, deaths, -c(day, month)) %>%
mutate(deaths = as.numeric(deaths))
}) %>%
mutate(month = recode(month, "JAN" = 1, "FEB" = 2, "MAR" = 3, "APR" = 4, "MAY" = 5, "JUN" = 6,
"JUL" = 7, "AGO" = 8, "SEP" = 9, "OCT" = 10, "NOV" = 11, "DEC" = 12)) %>%
mutate(date = make_date(year, month, day)) %>%
filter(date <= "2018-05-01")
library(lubridate)
library(tidyverse)
library(purrr)
library(pdftools)
library(lubridate)
fn <- system.file("extdata", "RD-Mortality-Report_2015-18-180531.pdf", package="dslabs")
dat <- map_df(str_split(pdf_text(fn), "\n"), function(s){
s <- str_trim(s)
header_index <- str_which(s, "2015")[1]
tmp <- str_split(s[header_index], "\\s+", simplify = TRUE)
month <- tmp[1]
header <- tmp[-1]
tail_index  <- str_which(s, "Total")
n <- str_count(s, "\\d+")
out <- c(1:header_index, which(n==1), which(n>=28), tail_index:length(s))
s[-out] %>%
str_remove_all("[^\\d\\s]") %>%
str_trim() %>%
str_split_fixed("\\s+", n = 6) %>%
.[,1:5] %>%
as_data_frame() %>%
setNames(c("day", header)) %>%
mutate(month = month,
day = as.numeric(day)) %>%
gather(year, deaths, -c(day, month)) %>%
mutate(deaths = as.numeric(deaths))
}) %>%
mutate(month = recode(month, "JAN" = 1, "FEB" = 2, "MAR" = 3, "APR" = 4, "MAY" = 5, "JUN" = 6,
"JUL" = 7, "AGO" = 8, "SEP" = 9, "OCT" = 10, "NOV" = 11, "DEC" = 12)) %>%
mutate(date = make_date(year, month, day)) %>%
filter(date <= "2018-05-01")
View(dat)
View(dat)
library(tidyverse)
library(dslabs)
resid <- ifelse(lm(margin~day, data = polls_2008)$resid > 0, "+", "-")
polls_2008 %>%
mutate(resid = resid) %>%
ggplot(aes(day, margin)) +
geom_smooth(method = "lm", se = FALSE, color = "black") +
geom_point(aes(color = resid), size = 3)
polls_2008$day
span <- 2
tmp <- dat %>%
crossing(center = dat$month) %>%
mutate(dist = abs(month - center)) %>%
filter(dist <= span)
tmp %>%
ggplot(aes(day, margin)) +
geom_point(data = polls_2008, size = 3, alpha = 0.5, color = "grey") +
geom_point(size = 2) +
geom_smooth(aes(group = center),
method = "lm", formula=y~1, se = FALSE)
mp %>%
ggplot(aes(date, deaths)) +
geom_point(data = dat, size = 3, alpha = 0.5, color = "grey") +
geom_point(size = 2) +
geom_smooth(aes(group = center),
method = "lm", formula=y~1, se = FALSE)
span <- 2
tmp <- dat %>%
crossing(center = dat$month) %>%
mutate(dist = abs(month - center)) %>%
filter(dist <= span)
tmp %>%
ggplot(aes(date, deaths)) +
geom_point(data = dat, size = 3, alpha = 0.5, color = "grey") +
geom_point(size = 2) +
geom_smooth(aes(group = center),
method = "lm", formula=y~1, se = FALSE)
ratings <- read.table(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
col.names = c("userId", "movieId", "rating", "timestamp"))
dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)
models <- c("glm", "lda",  "naive_bayes",  "svmLinear",
"gamboost",  "gamLoess", "qda",
"knn", "kknn", "loclda", "gam",
"rf", "ranger",  "wsrf", "Rborist",
"avNNet", "mlp", "monmlp",
"adaboost", "gbm",
"svmRadial", "svmRadialCost", "svmRadialSigma")
library(caret)
library(dslabs)
set.seed(1)
data("mnist_27")
fits <- lapply(models, function(model){
print(model)
train(y ~ ., method = model, data = mnist_27$train)
})
View(fits)
length(mnist_27$test$y)
c <- seq(1,23,1)
{confusionMatrix(factor(pred[,c]),mnist_27$test$y$overall["Accuracy"]
})
predictions <- sapply(c,function(c)
fits[[1]]2
predictions <- sapply(c,function(c)
{
+ confusionMatrix(factor(pred[,c]),mnist_27$test$y$overall["Accuracy"]})
confusionMatrix(factor(pred[,1], mnist_27$test$y)
confusionMatrix(factor(pred[,1], mnist_27$test$y)$overall["Accuracy"]
confusionMatrix(factor(pred[,1], mnist_27$test$y)$overall["Accuracy"]
2
confusionMatrix(factor(pred[,1]), mnist_27$test$y)$overall["Accuracy"]
rm(list = ls())
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
# edx 10M dataset:
# https://grouplens.org/datasets/edx/10m/
# http://files.grouplens.org/datasets/edx/ml-10m.zip
dl <- tempfile()
download.file("http://files.grouplens.org/datasets/edx/ml-10m.zip", dl)
ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
col.names = c("userId", "movieId", "rating", "timestamp"))
movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],
title = as.character(title),
genres = as.character(genres))
edx <- left_join(ratings, movies, by = "movieId")
# Validation set will be 10% of edx data
set.seed(1, sample.kind="Rounding")
# if using R 3.5 or earlier, use `set.seed(1)` instead
test_index <- createDataPartition(y = edx$rating, times = 1, p = 0.1, list = FALSE)
edx <- edx[-test_index,]
temp <- edx[test_index,]
# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>%
semi_join(edx, by = "movieId") %>%
semi_join(edx, by = "userId")
# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)
rm(dl, ratings, movies, test_index, temp, edx, removed)
head(edx)
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
dl <- tempfile()
download.file("http://files.grouplens.org/datasets/edx/ml-10m.zip", dl)
install.packages(c("car", "jsonlite", "qualtRics", "rvest", "stringr"))
library(qualtRics)
library(jsonlite)
library(rvest)
library(car)
library(stringr)
install.packages(c("car", "httr", "jsonlite", "qualtRics", "rvest", "stringr"))
install.packages(c("car", "httr", "jsonlite", "qualtRics", "rvest", "stringr"))
library(qualtRics)
library(jsonlite)
library(rvest)
library(car)
library(stringr)
headers <- c(
'X-API-TOKEN' = "**",
'Content-Type' = "application/json",
'Accept' = '*/*',
'accept-encoding' = 'gzip, deflate'
)
headers
######SV survey ID#####
##original sv<-"SV_24wCXBoW63NxQvH"
###chile sv<-"SV_1OdPqNOoApsuIdf"
###moze sie przyda sv<-"SV_9Go06eJvcpwNgHz"
###domestic https://surveys.az1.qualtrics.com/jfe/form/SV_eQy2KEpjbfFRbBX
sv<-"SV_eQy2KEpjbfFRbBX"
url <- paste("https://imercer.az1.qualtrics.com/API/v3/surveys/",sv,sep = "")
req <- httr::GET(url, httr::add_headers(headers))
View(req)
json <- httr::content(req, as = "text")
us <- fromJSON(json)
json
us
req
count_employee <- DataNA %>% group_by(Team) %>% select(Employee) %>% summarise_each(funs(n_distinct(Employee)))
install.packages("dplyr")
install.packages("tidyr")
install.packages("readr")
install.packages("rlang")
install.packages("DataCombine")
install.packages("plotly")
install.packages("rmarkdown")
is.installed <- function(mypkg) is.element(mypkg, installed.packages()[,1])
is.installed("assertthat")
is.installed("base64enc")
is.installed("BH")
is.installed("cli")
is.installed("clipr")
is.installed("colorspace")
is.installed("crayon")
is.installed("crosstalk")
is.installed("curl")
is.installed("data.table")
is.installed("DataCombine")
is.installed("digest")
is.installed("dplyr")
is.installed("evaluate")
is.installed("fansi")
is.installed("ggplot2")
is.installed("glue")
is.installed("gtable")
is.installed("hexbin")
is.installed("highr")
is.installed("hms")
is.installed("htmltools")
is.installed("htmlwidgets")
is.installed("httpuv")
is.installed("httr")
is.installed("jsonlite")
is.installed("knitr")
is.installed("labeling")
is.installed("later")
is.installed("lazyeval")
is.installed("magrittr")
is.installed("markdown")
is.installed("mime")
is.installed("munsell")
is.installed("openssl")
is.installed("pillar")
is.installed("pkgconfig")
is.installed("plogr")
is.installed("plotly")
is.installed("plyr")
is.installed("promises")
is.installed("purrr")
is.installed("R6")
is.installed("RColorBrewer")
is.installed("Rcpp")
is.installed("readr")
is.installed("reshape2")
is.installed("rlang")
is.installed("rmarkdown")
is.installed("scales")
is.installed("shiny")
is.installed("sourcetools")
is.installed("stringi")
is.installed("stringr")
is.installed("tibble")
is.installed("tidyr")
is.installed("tidyselect")
is.installed("tinytex")
is.installed("translations")
is.installed("utf8")
is.installed("viridisLite")
is.installed("withr")
is.installed("xfun")
is.installed("xtable")
is.installed("yaml")
library(XLConnect)
install.packages("rJava")
library(XLConnect)
headers <- c(
'X-API-TOKEN' = "GR_7VdPbx46ZyVF84l",
'Content-Type' = "application/json",
'Accept' = '*/*',
'accept-encoding' = 'gzip, deflate'
)
######SV survey ID#####
##original sv<-"SV_24wCXBoW63NxQvH"
###chile sv<-"SV_1OdPqNOoApsuIdf"
###moze sie przyda sv<-"SV_9Go06eJvcpwNgHz"
###domestic https://surveys.az1.qualtrics.com/jfe/form/SV_eQy2KEpjbfFRbBX
sv<-"SV_eQy2KEpjbfFRbBX"
url <- paste("https://imercer.az1.qualtrics.com/API/v3/surveys/",sv,sep = "")
req <- httr::GET(url, httr::add_headers(headers))
json <- httr::content(req, as = "text")
us <- fromJSON(json)
library(qualtRics)
library(jsonlite)
library(rvest)
library(car)
library(stringr)
headers <- c(
'X-API-TOKEN' = "GR_7VdPbx46ZyVF84l",
'Content-Type' = "application/json",
'Accept' = '*/*',
'accept-encoding' = 'gzip, deflate'
)
######SV survey ID#####
##original sv<-"SV_24wCXBoW63NxQvH"
###chile sv<-"SV_1OdPqNOoApsuIdf"
###moze sie przyda sv<-"SV_9Go06eJvcpwNgHz"
###domestic https://surveys.az1.qualtrics.com/jfe/form/SV_eQy2KEpjbfFRbBX
sv<-"SV_eQy2KEpjbfFRbBX"
url <- paste("https://imercer.az1.qualtrics.com/API/v3/surveys/",sv,sep = "")
req <- httr::GET(url, httr::add_headers(headers))
json <- httr::content(req, as = "text")
us <- fromJSON(json)
install.packages("shiny")
#
# This is a Shiny web application. You can run the application by clicking
# the 'Run App' button above.
#
# Find out more about building applications with Shiny here:
#
#    http://shiny.rstudio.com/
#
library(shiny)
# Define UI for application that draws a histogram
ui <- fluidPage(
# Application title
titlePanel("Old Faithful Geyser Data"),
# Sidebar with a slider input for number of bins
sidebarLayout(
sidebarPanel(
sliderInput("bins",
"Number of bins:",
min = 1,
max = 50,
value = 30)
),
# Show a plot of the generated distribution
mainPanel(
plotOutput("distPlot")
)
)
)
# Define server logic required to draw a histogram
server <- function(input, output) {
output$distPlot <- renderPlot({
# generate bins based on input$bins from ui.R
x    <- faithful[, 2]
bins <- seq(min(x), max(x), length.out = input$bins + 1)
# draw the histogram with the specified number of bins
hist(x, breaks = bins, col = 'darkgray', border = 'white')
})
}
# Run the application
shinyApp(ui = ui, server = server)
#
# This is a Shiny web application. You can run the application by clicking
# the 'Run App' button above.
#
# Find out more about building applications with Shiny here:
#
#    http://shiny.rstudio.com/
#
library(shiny)
# Define UI for application that draws a histogram
ui <- fluidPage(
# Application title
titlePanel("Old Faithful Geyser Data"),
# Sidebar with a slider input for number of bins
sidebarLayout(
sidebarPanel(
sliderInput("bins",
"Number of bins:",
min = 1,
max = 50,
value = 30)
),
# Show a plot of the generated distribution
mainPanel(
plotOutput("distPlot")
)
)
)
# Define server logic required to draw a histogram
server <- function(input, output) {
output$distPlot <- renderPlot({
# generate bins based on input$bins from ui.R
x    <- faithful[, 2]
bins <- seq(min(x), max(x), length.out = input$bins + 1)
# draw the histogram with the specified number of bins
hist(x, breaks = bins, col = 'darkgray', border = 'white')
})
}
# Run the application
shinyApp(ui = ui, server = server)
faithful[, 2]
runApp('H:/rshiny/test')
local({
# The directory where Pandoc will be extracted. Feel free
# to adjust this path as appropriate.
dir <- "~/rstudio-pandoc"
# The version of Pandoc to be installed.
version <- "2.7.1"
# Create and move to the requested directory.
dir.create(dir, showWarnings = FALSE, recursive = TRUE)
owd <- setwd(dir)
on.exit(setwd(owd), add = TRUE)
# Construct path to pandoc.
root <- "https://s3.amazonaws.com/rstudio-buildtools"
suffix <- sprintf("pandoc-%s-windows-x86_64.zip", version)
url <- file.path(root, "pandoc-rstudio", version, suffix)
# Download and extract pandoc.
file <- basename(url)
utils::download.file(url, destfile = file)
utils::unzip(file)
unlink(file)
# Write .Renviron to update the version of Pandoc used.
entry <- paste("RSTUDIO_PANDOC", shQuote(path.expand(dir)), sep = " = ")
contents <- if (file.exists("~/.Renviron")) readLines("~/.Renviron")
filtered <- grep("^RSTUDIO_PANDOC", contents, value = TRUE, invert = TRUE)
amended <- union(filtered, entry)
writeLines(amended, "~/.Renviron")
# Report change to the user.
writeLines("Updated .Renviron:\n")
writeLines(amended)
writeLines("\nPlease restart RStudio for these changes to take effect.")
})
months(as.Date(format(Sys.Date(), '%Y-%m-%01'))-210)
months(as.Date(format(Sys.Date(), '%Y-%m-%01'))-240)
#loading data
data <- read.csv("online_shoppers_intention.csv",header=TRUE)
# provide below path to working directory
setwd("C:/Users/filip-mordarski/Documents/filip/capstone/own project/Online-Shopper-s-intention-master")
#loading data
data <- read.csv("online_shoppers_intention.csv",header=TRUE)
class(data$Revenue)
# removing any rows with NA value
data <- data[complete.cases(data), ]
data %>%
summary(Revenue)
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(randomForest)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(lubridate)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(dplyr)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(ggplot2)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(tinytex)) install.packages("data.table", repos = "http://cran.us.r-project.org")
data %>%
summary(Revenue)
data %>%
summarise(Revenue)
data %>%
summarize(Revenue)
summary(data$Revenue)
data$Revenue <- as.factor(data$Revenue)
y <- data$Revenue
# Create trainset and test set
set.seed(1)
test_index <- createDataPartition(y, times = 1, p = 0.1, list = FALSE)
test_set <- data[test_index, ]
train_set <- data[-test_index, ]
data %>%
group_by(Revenue)
summarise(FrequencyCount=n())
data %>%
group_by(Revenue)
summarise(FrequencyCount=n(Revenue))
data %>%
group_by(Revenue)
summarise(FrequencyPerc=mean(Revenue))
data %>%
summarise(FrequencyPerc=mean(Revenue))
##loading data
data <- read.csv("online_shoppers_intention.csv",header=TRUE)
# removing any rows with NA value
data <- data[complete.cases(data), ]
data %>%
summarise(FrequencyPerc=mean(Revenue))
y <- data$Revenue
# Create trainset and test set
set.seed(1)
test_index <- createDataPartition(y, times = 1, p = 0.1, list = FALSE)
test_set <- data[test_index, ]
train_set <- data[-test_index, ]
data %>%
summarise_each(Revenue,mean)
data %>%
summarise(FreqPercTrue=mean(Revenue),FreqPercFalse=1-mean(Revenue))
data %>%
summarise(FreqPercTrue=mean(Revenue),FreqPercFalse=1-mean(Revenue)) %>%
summarise(FreqPercTrue=n())
th frequency percentage if shopper will generate revenue
data %>%
summarize(FreqPercTrue=mean(Revenue),FreqPercFalse=1-mean(Revenue))
